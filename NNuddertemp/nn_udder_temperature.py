# -*- coding: utf-8 -*-
"""NN udder temperature.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tIkL8yPXZ9Q9QMrOyCtYqoVKqPxj5yS_

NEURAL NETWORK FOR THE UDDER TEMPERATURE
"""

#importing dependencies
import sys
import pandas as pd
import numpy as np
import sklearn
import matplotlib.pyplot as plt

import keras
from sklearn.model_selection import train_test_split

"""Data preprocessing"""

#Data preprocessing
udder_temp = pd.read_csv('/content/uddertemperature.csv')
udder_temp.head()

# Renaming some of the columns 
udder_temp = udder_temp.rename(columns={'Status':'target'})

#data cleaning
#removing null values
udder_temp = udder_temp.dropna()
udder_temp.isnull().sum()

#check for missing values
missing_values = udder_temp.isnull().sum().sort_values(ascending = False)
missing_values = missing_values[missing_values > 0]/udder_temp.shape[0] # normalize
print(f'{missing_values *100} %')

#replace the strings in target column with corresponding numbers
udder_temp =udder_temp.replace({'clinical': 2, 'subclinical': 1, 'Healthy': 0})
udder_temp.head()

# checking the distribution of the target variable
udder_temp['target'].value_counts()

"""'clinical': 2, 'subclinical': 1, 'Healthy': 0

Splitting the target and features
"""

X = udder_temp.drop(columns='target',axis = 1)
y = udder_temp['target']

"""spliting data into testing and training data"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,random_state=2)

print(X.shape,X_train.shape,X_test.shape)

#Feature scaling
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_train_std = scaler.fit_transform(X_train)
X_test_std = scaler.fit_transform(X_test)

print(X_train_std)



"""BUILDING A NUERAL NETWORK"""

#importing tensorflow and keras
import tensorflow as tf
tf.random.set_seed (3)
from tensorflow import keras

from tensorflow.python.ops.math_ops import sigmoid
# setting up the layers of the nueral network
model = keras.Sequential([
    keras.layers.Flatten(input_shape=(1,)),
    keras.layers.Dense(20,activation = 'relu'),
    keras.layers.Dense(30,activation = 'relu'),
    keras.layers.Dense(3, activation = 'sigmoid')
])

#compiling the nueral network
model.compile(loss='sparse_categorical_crossentropy', 
               optimizer= 'adam', 
               metrics=['accuracy']
               )

"""Training the Nueral Network"""

history = model.fit(X_train_std,y_train, validation_split=0.1, epochs = 100)

"""VISUALISING ACCURACY AND LOSS"""

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')

plt.legend(['training data','validation data'], loc ='lower right')

"""Accuracy of the model on test data"""

loss, accuracy = model.evaluate(X_test_std,y_test)
print(accuracy)

#predictioon
y_pred = model.predict(X_test_std)
print(y_pred)

#converting the prediction probability to class labels
y_pred_labels = [np.argmax(i) for i in y_pred]
print(y_pred_labels)

"""BUILDING THE PREDICTIVE SYSTEM"""

input_temp = (34.5)
#converting the input data into a numpyarray 
input_udder_temp = np.asarray(input_temp)

#reshaping the numpy array
input_temp_reshaped = input_udder_temp.reshape(1,-1)
input_temp_reshaped.shape

#standardizing the data 
input_temp_std = scaler.transform(input_temp_reshaped)

prediction = model.predict(input_temp_std)

print(prediction)
prediction_label = [np.argmax(prediction)]
print(prediction_label)
if(prediction_label[0]==2):
    print("clinical Mastitis Detected")
  
elif (prediction_label[0]==1):
    print ("subclinical mastitis Detected")

else:
    print("Healthy animal and no mastitis Detected")

"""SAVING THE TRAINED MODEL"""

import pickle
filename = 'NNuddertemperature_model.pkl'
pickle.dump(model,open(filename,'wb'))

